row.names(x)<-x_nam
x
?merge
merge(x,m)
x
merge(m,x)
merge(x,m,by=0,all=TRUE)
x
m
m
m+x
#Adjacency matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
m
m[1,]
x[1,]
m+x[1,]
(m+x)[1,]
(m+x)
m+x
x<-data.frame(matrix(0,ncol=2,nrow=2))
x
colnames(x)<-c("a","b")
x
y<-data.frame(matrix(1,ncol=2,nrow=2))
colnames(y)<-c("a","b")
x
y
x+y
y+x
x
y
row.names(x)<-c("a","b")
row.names(y)<-c("a","b")
x
y
x+y
merge(x,y)
x+y
y[1,]
x+y[1,]
x+(y[1,])
(x)+(y[1,])
x
y
y=y[1,]
x
y
x+y
x+y
x[1]
x[a]
x[[a]]
x[["a"]]
x["a"]
x[["a"]]
x["a",]
x["a",]<-y
x
x
y
y<-y[,-1]
y
as.data.frame(y,row.names = c("a"))
y=as.data.frame(y,row.names = c("a"))
colnames(y)<-c("b")
y
x
x+y
x["a",]<-y["a",]
x
y
y["a","b"]<-2
y
x["a",]<-y["a",]
x
x
x["a",]<-2
x
x["a",]<-1
x
x
x["a","b"]<-2
x
y
y["a","b"]
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
#Checking for relative abundance structure
r_s=c()
for (i in 1:229){
r_s=c(r_s,sum(data[i,]))
}
print(var(r_s))
remove(r_s,i,data)
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
i=1
#for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool))
print(x_nam) #Row name
print(y_nam) #Column names with correlation >0.05
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
opt_m
rmse<-function(model,col=i,data=c1_data){
error=sqrt(mean((predict(model,data)-data[[col]])^2))
return(error)
}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
error=rmse(model1,col=i)
print(error)
#Adjacency matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
for(cl in colname(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
m
x
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
i=1
#for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool))
print(x_nam) #Row name
print(y_nam) #Column names with correlation >0.05
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#Adjacency matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
print(opt_m)
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
print(opt_m)
rmse<-function(model,col=i,data=c1_data){
error=sqrt(mean((predict(model,data)-data[[col]])^2))
return(error)
}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
error=rmse(model1,col=i)
print(error)
m
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
rmse<-function(model,col=i,data=c1_data){
error=sqrt(mean((predict(model,data)-data[[col]])^2))
return(error)
}
for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
print(opt_m)
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
error=rmse(model1,col=i)
print(error)
}
x
x
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
rmse<-function(model,col=i,data=c1_data){
error=sqrt(mean((predict(model,data)-data[[col]])^2))
return(error)
}
for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
error=rmse(model1,col=i)
print(error)
}
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
#Checking for relative abundance structure
r_s=c()
for (i in 1:229){
r_s=c(r_s,sum(data[i,]))
}
print(var(r_s))
remove(r_s,i,data)
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
rmse<-function(model,col=i,data=c1_data){
error=sqrt(mean((predict(model,data)-data[[col]])^2))
return(error)
}
for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
error=rmse(model1,col=i)
print(error)
}
x_nam
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
y_nam
y_nam == 0
y_nam == ""
y_nam == " "
y_nam
y_nam[1]
y_nam == character(0)
y_nam == character(0)
y_nam == character(1)
class(y_nam)
y_nam
is.empty(y_nam)
is.character(y_nam)
identical(y_nam,"")
identical(y_nam,character(0))
if(identical(y_nam,character(0)) == TRUE){y_nam="."}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
error=rmse(model1,col=i)
print(error)
for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){y_nam="."}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
error=rmse(model1,col=i)
print(error)
}
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
rmse<-function(model,col=i,data=c1_data){
error=sqrt(mean((predict(model,data)-data[[col]])^2))
return(error)
}
for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){y_nam="."}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
glm(form,data=c1_data )
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model1$`(weights)`,type="kfold",B=10)
cvm<-cvrisk(model1,folds=f)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
error=rmse(model1,col=i)
print(error)
}
warnings()
warnings()
m
m[539,]
write.csv(m,"/tmp/matrix.csv")
m
q()
