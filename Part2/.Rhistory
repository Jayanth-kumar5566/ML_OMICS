legend(150,1000,legend = c("var","error"))
legend(150,1500,legend = c("var","error"))
plot(y,col="red",pch=19)
points(er,col="blue",pch=18)
plot(er,y)
plot(y,er)
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
p_m<-data.frame(p_m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
colnames(p_m)<-colnames(c1_data)
r2<-function(model,col=i,data=c1_data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
i
i=1
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){next}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=100,nu=0.05,trace=TRUE))
ri=c(ri,tail(model1$risk(),n=1))
m=c()
for (i in 1:100){
cvm<-cvrisk(model1,mc.cores=4)
opt_m<-mstop(cvm)
m=c(m,opt_m)
}
m_var=c(m_var,var(m))
m
var(m)
opt_m
model1
model1[1]
model1[0]
model1
model1
model1[100]
m=c()
r=c()
for (j in 1:100){
cvm<-cvrisk(model1,mc.cores=4)
opt_m<-mstop(cvm)
m=c(m,opt_m)
r=c(r,r2(model1[opt_m],col=i))
model1[100]
}
r
model1
m
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
p_m<-data.frame(p_m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
colnames(p_m)<-colnames(c1_data)
r2<-function(model,col=i,data=c1_data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
m_var=c()
r2_var=c()
ri_var=c()
i=1
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){next}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=100,nu=0.05,trace=TRUE))
ri=c(ri,tail(model1$risk(),n=1))
m=c()
r=c()
for (j in 1:100){
cvm<-cvrisk(model1,mc.cores=4)
opt_m<-mstop(cvm)
m=c(m,opt_m)
model1[opt_m]
r=c(r,r2(model1,col=i))
model1[100]
}
m_var=c(m_var,var(m))
r2_var=c(r2_var,var(r))
m_var
r2_var
r2
r
m
ri
m2_var
m_var
write.csv(m_var,"\tmp\x.csv")
write.csv(m_var,"/tmp\x.csv")
write.csv(m_var,"/tmp/x.csv")
p
p_m
p_m["Actinobacillus",]
p.adjust(p_m["Actinobacillus",],method="fdr")
p.adjust(p_m["Actinobacillus",],method="fdr")
p.adjust(p_m["Actinobacillus",],method="fdr")
p.adjust(p_m["Actinobacillus",],method="BH")
p.adjust(p_m["Actinobacillus",],method="fdr")
as.numeric(p_m["Actinobacillus",])
as.numeric(p_m["Actinobacillus",])
p_m["Actinobacillus",]
p_m
p_m
p_m["Actinomyces",]
p_m["Atopobium",]
p_m["Zymoseptoria",]
p_m
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
#Checking for relative abundance structure
r_s=c()
remove(r_s,i,data)
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
p_m<-data.frame(p_m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
colnames(p_m)<-colnames(c1_data)
r2<-function(model,col=i,data=c1_data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
i=
1
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){next}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10)
cvm<-cvrisk(model1,folds=f,mc.cores=4)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
error=r2(model1,col=i)
if (error<0.5){next}
i=2
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
p_m<-data.frame(p_m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
colnames(p_m)<-colnames(c1_data)
r2<-function(model,col=i,data=c1_data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
for (i in 1:539){
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){next}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10)
cvm<-cvrisk(model1,folds=f,mc.cores=4)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
error=r2(model1,col=i)
if (error<0.5){next}
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
#Bootstrap distribution
#------------Using boot-----------------
library(boot)
boot.stat<-function(data,indices,m_stop,form,x_nam){
data<-data[indices,]
mod<-glmboost(form,data=data,family = Gaussian(),
center=FALSE,control = boost_control(mstop=m_stop,nu=0.05,trace=TRUE))
wghts<-coef(mod,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
return(x)
}
model.boot<-boot(c1_data,boot.stat,100,m_stop=opt_m,form=form,x_nam=x_nam)
#-----------Permutation with renormalization-------------
#copy of the data
c1_data_p=c1_data
out_comb<-x
#permutation
counter=0
while (counter<100){
c1_data_p[[x_nam]]<-sample(c1_data_p[[x_nam]])
#renormalization
c1_data_p=(c1_data_p/rowSums(c1_data_p))*200
out<-boot.stat(c1_data_p,indices = 1:dim(c1_data)[1],m_stop=opt_m,form=form,x_nam=x_nam)
out_comb=rbind(out_comb,out)
counter = counter + 1
}
out_comb<-out_comb[-1,]
#Comparing two distributions
for (i in 1:dim(out_comb)[2]){
p=wilcox.test(model.boot$t[,i],out_comb[,i],alternative = "two.sided",paired = FALSE)$p.value
p_m[x_nam,colnames(out_comb)[i]]<-p
}
}
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
p_m<-data.frame(p_m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
colnames(p_m)<-colnames(c1_data)
r2<-function(model,col=i,data=c1_data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
i=2
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){next}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10)
cvm<-cvrisk(model1,folds=f,mc.cores=4)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
error=r2(model1,col=i)
if (error<0.5){next}
i=8
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
cool=which(ind1, arr.ind = T)
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
if(identical(y_nam,character(0)) == TRUE){next}
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10)
cvm<-cvrisk(model1,folds=f,mc.cores=4)
opt_m<-mstop(cvm)
if(opt_m==0){opt_m=1}
#Choosing the optimal model
model1[opt_m]
error=r2(model1,col=i)
if (error<0.5){next}
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
#Bootstrap distribution
#------------Using boot-----------------
library(boot)
boot.stat<-function(data,indices,m_stop,form,x_nam){
data<-data[indices,]
mod<-glmboost(form,data=data,family = Gaussian(),
center=FALSE,control = boost_control(mstop=m_stop,nu=0.05,trace=TRUE))
wghts<-coef(mod,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
return(x)
}
model.boot<-boot(c1_data,boot.stat,100,m_stop=opt_m,form=form,x_nam=x_nam)
#-----------Permutation with renormalization-------------
#copy of the data
c1_data_p=c1_data
out_comb<-x
#permutation
counter=0
while (counter<100){
c1_data_p[[x_nam]]<-sample(c1_data_p[[x_nam]])
#renormalization
c1_data_p=(c1_data_p/rowSums(c1_data_p))*200
out<-boot.stat(c1_data_p,indices = 1:dim(c1_data)[1],m_stop=opt_m,form=form,x_nam=x_nam)
out_comb=rbind(out_comb,out)
counter = counter + 1
}
out_comb<-out_comb[-1,]
#Comparing two distributions
for (i in 1:dim(out_comb)[2]){
p=wilcox.test(model.boot$t[,i],out_comb[,i],alternative = "two.sided",paired = FALSE)$p.value
p_m[x_nam,colnames(out_comb)[i]]<-p
}
x_nam
p_m
p_m[x_nam,]
as.numeric(p_m[x_nam,])
p.adjust(as.numeric(p_m[x_nam,]),method = "fdr")
p.adjust(p_m[x_nam,],method = "fdr")
colnames()
colnames(out_comb)
#correction of multiple comparision
for (i in colnames(p_m)){
p_m[i,]<-p.adjust(p_m[i,],method = "fdr")
}
p_m
dim(out_comb)
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
library(mboost)
# For c1_data
cr_mat=cor(c1_data,method = "spearman") #Compute Spearman Correlation
cr_mat[is.na(cr_mat)]<-0  # Assign 0 to NA values(NA due to zero STD)
#Adjacency matrix and p-value matrix creation
m=matrix(0,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
p_m=matrix(2,ncol=dim(cr_mat)[1],nrow=dim(cr_mat)[2])
m<-data.frame(m,row.names = colnames(c1_data))
p_m<-data.frame(p_m,row.names = colnames(c1_data))
colnames(m)<-colnames(c1_data)
colnames(p_m)<-colnames(c1_data)
r2<-function(model,col=i,data=c1_data){
sse=sum((predict(model,data)-data[[col]])^2)
tss=sum((data[[col]]-mean(data[[col]]))^2)
error=1-(sse/tss)
return(error)
}
i=1
x_nam=rownames(cr_mat)[i]
ind1=abs(cr_mat[i,]) > 0.05 & abs(cr_mat[i,]) != 1
ind1
cool=which(ind1, arr.ind = T)
cool
y_nam=rownames(as.data.frame(cool)) #Column names with correlation >0.05
y_nam
print(x_nam) #Row name
#Formula
form=as.formula(paste(x_nam,paste(y_nam,collapse = "+"),sep="~"))
#GLMBoosting and Model Tuning, Depends on randomness
model1<-glmboost(form,data=c1_data,family = Gaussian(),
center=TRUE,control = boost_control(mstop=200,nu=0.05,trace=TRUE))
#Induces randomness, can loop and take the nearest average integer
f<-cv(model.weights(model1),type="kfold",B=10)
cvm<-cvrisk(model1,folds=f,mc.cores=4)
opt_m<-mstop(cvm)
#Choosing the optimal model
model1[opt_m]
error=r2(model1,col=i)
wghts<-coef(model1,which="")
x<-t(as.data.frame(wghts[-1]))
x
row.names(x)<-x_nam
x
#Appending the coefficient matrix to adjacency matrix
for(cl in colnames(x)){
m[x_nam,cl]<-x[x_nam,cl]
}
#Bootstrap distribution
#------------Using boot-----------------
library(boot)
boot.stat<-function(data,indices,m_stop,form,x_nam){
data<-data[indices,]
mod<-glmboost(form,data=data,family = Gaussian(),
center=FALSE,control = boost_control(mstop=m_stop,nu=0.05,trace=TRUE))
wghts<-coef(mod,which="")
x<-t(as.data.frame(wghts[-1]))
row.names(x)<-x_nam
return(x)
}
model.boot<-boot(c1_data,boot.stat,100,m_stop=opt_m,form=form,x_nam=x_nam)
x
#-----------Permutation with renormalization-------------
#copy of the data
c1_data_p=c1_data
out_comb<-x
out_comb
#permutation
counter=0
while (counter<100){
c1_data_p[[x_nam]]<-sample(c1_data_p[[x_nam]])
#renormalization
c1_data_p=(c1_data_p/rowSums(c1_data_p))*200
out<-boot.stat(c1_data_p,indices = 1:dim(c1_data)[1],m_stop=opt_m,form=form,x_nam=x_nam)
out_comb=rbind(out_comb,out)
counter = counter + 1
}
out_comb<-out_comb[-1,]
out_comb
#Comparing two distributions
p_test<-c()
dim(out_comb)[2]
dim(out_comb)
q()
#Reading the dataset
data=read.csv("data_combined.csv")
rownames(data)<-data$PatientID
data$PatientID<-NULL
c1_data=subset(data,x==1)
c2_data=subset(data,x==2)
c1_data$x<-NULL
c2_data$x<-NULL
c1_data
colSums(c1_data)
write.csv(colSums(c1_data),"./Plotting/c1_abund.csv")
